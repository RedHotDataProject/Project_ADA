{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Food Facts - Cleanse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Explore-the-data\" data-toc-modified-id=\"Explore-the-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Explore the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Display-number-of-non-NaN-entries-per-column\" data-toc-modified-id=\"Display-number-of-non-NaN-entries-per-column-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Display number of non-NaN entries per column</a></span></li></ul></li><li><span><a href=\"#Cleanse-data\" data-toc-modified-id=\"Cleanse-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Cleanse data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Unitize-tags\" data-toc-modified-id=\"Unitize-tags-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Unitize tags</a></span><ul class=\"toc-item\"><li><span><a href=\"#Countries-tags\" data-toc-modified-id=\"Countries-tags-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Countries tags</a></span></li><li><span><a href=\"#Labels-tags\" data-toc-modified-id=\"Labels-tags-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Labels tags</a></span></li><li><span><a href=\"#Store-labels-tags\" data-toc-modified-id=\"Store-labels-tags-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Store labels tags</a></span></li><li><span><a href=\"#Food-category-tags\" data-toc-modified-id=\"Food-category-tags-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Food category tags</a></span></li></ul></li></ul></li><li><span><a href=\"#Carbon-footprint-dataset\" data-toc-modified-id=\"Carbon-footprint-dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Carbon footprint dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-the-data\" data-toc-modified-id=\"Loading-the-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Loading the data</a></span></li></ul></li><li><span><a href=\"#Concat-price-info\" data-toc-modified-id=\"Concat-price-info-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Concat price info</a></span><ul class=\"toc-item\"><li><span><a href=\"#OpenFoodFacts-dataset\" data-toc-modified-id=\"OpenFoodFacts-dataset-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>OpenFoodFacts dataset</a></span></li><li><span><a href=\"#Carbon-footprint-dataset\" data-toc-modified-id=\"Carbon-footprint-dataset-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Carbon footprint dataset</a></span></li></ul></li><li><span><a href=\"#Remove-negative-entries\" data-toc-modified-id=\"Remove-negative-entries-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Remove negative entries</a></span></li><li><span><a href=\"#Write-clean-data-frame-to-CSV-file\" data-toc-modified-id=\"Write-clean-data-frame-to-CSV-file-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Write clean data frame to CSV file</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Our generated code\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from libs import exploring as explore\n",
    "from libs import visualising as visualize\n",
    "from libs import cleansing as cleanse\n",
    "\n",
    "PLOT = True\n",
    "RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "open_food_facts_csv_file = \"./data/en.openfoodfacts.org.products.csv\"\n",
    "\n",
    "# Load list of columns (external file) that are loaded into pyspark\n",
    "data = []\n",
    "with open(\"./data/cleanse/columns_to_import.txt\", \"r\") as json_data:\n",
    "    columns_to_import = json.load(json_data)\n",
    "    columns_to_import\n",
    "\n",
    "\n",
    "food_facts_pd = pd.read_csv(open_food_facts_csv_file,\n",
    "                            delimiter=\"\\t\",\n",
    "                            usecols=columns_to_import.keys(),\n",
    "                            dtype=columns_to_import)\n",
    "\n",
    "food_facts_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary_string = \"The dataset now comprises {} entries, of which we have {} features.\"\n",
    "data_summary_string.format(food_facts_pd.shape[0], food_facts_pd.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "We begin with taking a quick look on the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display number of non-NaN entries per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_entries = pd.DataFrame({'columns' : food_facts_pd.columns,\n",
    "                             'not nan_values' : [food_facts_pd[c].count() for c in food_facts_pd]\n",
    "                            })\n",
    "\n",
    "# Plot NaNs counts\n",
    "if PLOT:\n",
    "    null_entries.set_index('columns').plot(kind='barh', figsize=(10, 10))\n",
    "    plt.title(\"Not null values count in each column\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that there are many entries are missing in this data set. Especially the *carbon-foorprint_100g* column is almost empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at the dataset growth over the years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    food_facts_pd['created_datetime'] = food_facts_pd['created_datetime'].apply(pd.to_datetime, args=('coerce',))\n",
    "    food_facts_pd['created_yyyy'] = food_facts_pd[\"created_datetime\"].dt.year\n",
    "    visualize.plot_grouped_counts(food_facts_pd, 'created_yyyy', \n",
    "                                  ['code', 'main_category', 'carbon-footprint_100g', 'nutrition-score-fr_100g'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code line in the above plot denotes the overall count of entries that was created in the respective year. We can see that the popularity of the database has strongly increased over the past years, where the first mobile applications to use the database emerged. We only considered products that were created up to November 2018, which should be attributed to the decline in growth in this year.\n",
    "\n",
    "We can further observe that the categorization and nutrition score computation of products develops disproportionately lower than the number of products, and is more complete for products that are in the database longer.\n",
    "\n",
    "For our analysis, we can only use entries that have at least a product name, country tag, manufacturing and purchase place, store, and a created date tag. Unfortunately, we have to drop all columns, that lack these entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rows_inital = food_facts_pd.shape[0]\n",
    "\n",
    "# Drop entries with missing entries in one of our main-features\n",
    "essential_columns = ['created_t', \n",
    "                     'product_name', \n",
    "                     'countries_en', \n",
    "                     'categories_en', \n",
    "                     'stores',\n",
    "                     'manufacturing_places', \n",
    "                     'purchase_places']\n",
    "food_facts_pd = food_facts_pd.dropna(subset=essential_columns, )\n",
    "\n",
    "no_rows_reduced_nan = food_facts_pd.shape[0]\n",
    "\n",
    "# Also drop duplicated values (indentify based on index (barcode))\n",
    "food_facts_pd = food_facts_pd.drop_duplicates()\n",
    "\n",
    "no_rows_reduced_duplicates = food_facts_pd.shape[0]\n",
    "\n",
    "print(\"{} entries were dropped, {} of those were duplicates.\"\\\n",
    "      .format(no_rows_inital-no_rows_reduced_duplicates, \n",
    "              no_rows_reduced_nan-no_rows_reduced_duplicates)\n",
    "     )\n",
    "print(data_summary_string.format(food_facts_pd.shape[0], \n",
    "                                 food_facts_pd.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puhh, that was though. From now on, we are going to rescue the data and enrich wherever we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs with emptry string\n",
    "food_facts_pd = food_facts_pd.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that we are not really keen of are the language indicators, so we are going to remove those prefixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd.categories_en = food_facts_pd.categories_en.apply(cleanse.remove_language_indicator)\n",
    "food_facts_pd.main_category = food_facts_pd.main_category.apply(cleanse.remove_language_indicator)\n",
    "food_facts_pd.countries_en = food_facts_pd.countries_en.apply(cleanse.remove_language_indicator)\n",
    "food_facts_pd.labels_en = food_facts_pd.labels_en.apply(cleanse.remove_language_indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unitize tags\n",
    "Many parts of the data are categorizations based on tags. However, those tags are in a variety of languages and string formattings, so in order to use them we attempt to group tags that hint to the same property and map them to a common indicator. \n",
    "\n",
    "Every column of the data set requires special treatment, as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Countries tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note :  \n",
    "- purchase_places and countries_en are the same though \"countries_en\" has more entries\n",
    "- manufacturing_places and origins are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"_Countries_\" is a csv file modified in the \"_Country__names.ipynb_\" file from the source (available at https://mledoze.github.io/countries/) that maps country names in a multitude of languages to their English counterpart. We need to harmonise country names (and push them to English since many entries use French and German). The columns requiring our attentions are the following:\n",
    "- origins\n",
    "- manufacturing_places\n",
    "- countries_en\n",
    "\n",
    "Note that each have a respective redundant column : origins_tags, manufacturing_places_tags and purchase_places. We are going to filter and group those by a function in our _cleansing.py_ library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load analyse file\n",
    "countries = pd.read_csv(\"./data/country_lookup.csv\")[['name', 'cca2', 'alias', 'Forced']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's attack the Open Food Fact database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following commands are only run on demand, if the analysis has to be performed again. \n",
    "# The result are cached in ./data/food_facts_pd_countries_names.csv\n",
    "RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( RUN ):\n",
    "    food_facts_pd['origins_cleaned'] = food_facts_pd.origins\\\n",
    "        .apply(lambda x: cleanse.tag_filter(x, countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( RUN ):\n",
    "    food_facts_pd['manufacturing_place_cleaned'] = food_facts_pd.manufacturing_places\\\n",
    "        .apply(lambda x: cleanse.tag_filter(x, countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( RUN ):\n",
    "    food_facts_pd['purchase_places_cleaned'] = food_facts_pd.purchase_places\\\n",
    "        .apply(lambda x: cleanse.tag_filter(x, countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache results\n",
    "if( RUN ):\n",
    "    food_facts_pd_countries_names = food_facts_pd[['origins_cleaned', \n",
    "                                                   'manufacturing_place_cleaned', \n",
    "                                                   'purchase_places_cleaned']\n",
    "                                                 ]\n",
    "    food_facts_pd_countries_names.to_csv(\"./data/food_facts_pd_countries_names.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels tags\n",
    "The harmonisation of label tags is provided on the [OpenFoodFacts website](https://en.wiki.openfoodfacts.org/Global_labels_taxonomy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unitze labels\n",
    "with open('./data/cleanse/taxonomies.json', 'r') as json_data:\n",
    "    labels_lookup = cleanse.to_lookup(json.load(json_data))\n",
    "food_facts_pd.labels_en = food_facts_pd.labels_en.\\\n",
    "    apply(lambda x: \",\".join([labels_lookup[z] for z in x.split(',')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    food_facts_pd['labels_en'] = food_facts_pd.labels_en\\\n",
    "        .apply(lambda x: cleanse.clean_tags_for_regex(x))\n",
    "    _ = visualize.plot_occurrences_of_distinct_values(food_facts_pd, 'labels_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store labels tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unitize store labels\n",
    "with open('./data/cleanse/stores_lookup.json', 'r') as json_data:\n",
    "    stores_lookup = cleanse.to_lookup(json.load(json_data))\n",
    "food_facts_pd.stores = food_facts_pd.stores.fillna(\"\")\\\n",
    "    .apply(lambda x: \",\".join([stores_lookup[z] for z in x.split(',')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    food_facts_pd['stores'] = food_facts_pd.stores\\\n",
    "        .apply(lambda x: cleanse.clean_tags_for_regex(x))\n",
    "    _ = visualize.plot_occurrences_of_distinct_values(food_facts_pd, 'stores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Food category tags\n",
    "For the food category, we used human intelligence to assign subcategory to a theme based on their main ingredient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group categories by user-defined themes\n",
    "with open('./data/cleanse/categories_en_lookup.json', 'r') as json_data:\n",
    "    categories_en = json.load(json_data)\n",
    "categories_en_lookup = cleanse.to_lookup(categories_en)\n",
    "food_facts_pd.main_category = food_facts_pd.categories_en.\\\n",
    "    apply(cleanse.group_categories, args=[categories_en_lookup]).\\\n",
    "    apply(cleanse.filter_others, args=[list(categories_en.keys())])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    _ = visualize.plot_occurrences_of_distinct_values(food_facts_pd, 'main_category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carbon footprint dataset\n",
    "\n",
    "Because the food facts database lacks carbon footprint specifications, we got random samples of products from Eaternity database. Unfortunately, we were not allowed access to the API before purchasing a 2000 CHF license. However, we were granted a dataset of carbon footprints for a random subset of products. These products have complete carbon footprint support, but therefore lack indication of production and purchasing countries as well as ingredients for computing the nutrition grades.\n",
    "\n",
    "Let's still take a quick look at the Carbon Footprint database, that we have obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "carbon_footprint_categories_csv_file = \"./data/carbon_footprint_categories.csv\"\n",
    "\n",
    "eaternity_pd = pd.read_csv(carbon_footprint_categories_csv_file,delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match categories to the same themes as for the OpenFoodFacts\n",
    "with open('./data/cleanse/categories_en_lookup.json', 'r') as json_data:\n",
    "    categories_en = json.load(json_data)\n",
    "\n",
    "# Group categories by themes\n",
    "categories_en_lookup = cleanse.to_lookup(categories_en)\n",
    "eaternity_pd['category_en'] = eaternity_pd.category_en.\\\n",
    "    apply(cleanse.group_categories, args=[categories_en_lookup]).\\\n",
    "    apply(cleanse.filter_others, args=[list(categories_en.keys())])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to OpenFoodFacts correspondences\n",
    "eaternity_pd.rename(columns={'Title':'product_name',\n",
    "                            'CO2-Value [gram CO2/serving]':'carbon-footprint_100g',\n",
    "                            'ENERC':'energy_100g', \n",
    "                            'category_en' : 'main_category'},\n",
    "                             inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have {0} ecological features for {1} products.'\\\n",
    "      .format(eaternity_pd.shape[1], \n",
    "              eaternity_pd.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "null_entries = pd.DataFrame({'columns' : eaternity_pd.columns,\n",
    "                             'not nan_values' : [eaternity_pd[c].count() for c in eaternity_pd]\n",
    "                            })\n",
    "\n",
    "# Plot NaNs counts\n",
    "if PLOT:\n",
    "    null_entries.set_index('columns').plot(kind='barh', figsize=(10, 10))\n",
    "    plt.title(\"Not null values count in each column\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that all the columns of the carbon footprint database from Eaternity are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    _ = visualize.plot_occurrences_of_distinct_values(eaternity_pd, 'main_category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the categories, there are mainly vegetables and condiments. Once we will match with the Open Food Facts database, we will have carbon footprint of food/meals derived from vegetables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = eaternity_pd['CO2-Value [gram CO2/serving]'].hist(bins=10)\n",
    "# ax.set_xlabel('Carbon footprint')\n",
    "# ax.set_ylabel('Occurencies')\n",
    "# ax.set_title('Distribution of the carbon ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the carbon footprint of each product. Because our sample is small (around 700 products) and doesn't really match with the Food Facts Database, we will take care of the categories. Thus, we will extract the categories from [Codecheck website](https://www.codecheck.info/) (Webscraper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat price info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also searched online shops for price information about some of the products, that we are going to merge in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenFoodFacts dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\"./web_crawler/data/prices_carbon.csv\", dtype={'code':object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_reduced = prices[['product_name', 'price_per_100g', 'store_currency']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the OpenFoodFacts code is not necessarily a global barcode for the product, we had to match the products from the online stores and the entries of the database by teh product name. To be consistent with that method, we merge the prices by the product name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd = pd.merge(food_facts_pd, prices_reduced, on='product_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Product prices successfully merged: {}\".format(food_facts_pd.price_per_100g.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carbon footprint dataset\n",
    "The same process, we repeated for the Eaternity dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\"./web_crawler/data/prices.csv\", dtype={'code':object})\n",
    "prices_reduced = prices[['product_name', 'price_per_100g', 'store_currency']].dropna()\n",
    "eaternity_pd = pd.merge(eaternity_pd, prices_reduced, on='product_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Product prices successfully merged: {}\".format(eaternity_pd.price_per_100g.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove negative entries\n",
    "We have few numerical features, which are the calories (energy), and price per 100g of the product. These values are due to physical or economic laws non-negative and hence corrupted, which is why we are going to make sure of this in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_columns = food_facts_pd.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns\n",
    "\n",
    "# food_facts_pd[numeric_columns] = food_facts_pd[numeric_columns].where(food_facts_pd[numeric_columns] >= 0, np.NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write clean data frame to CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : country names harmonised are available in ./data/food_facts_pd_countries_names.csv (note the additional code to go back to a list of strings). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply country name filter\n",
    "\n",
    "# Load lookup file\n",
    "countries_names= pd.read_csv(\"./data/food_facts_pd_countries_names.csv\")\n",
    "\n",
    "countries_names['origins_cleaned'] = \\\n",
    "                        countries_names.origins_cleaned.apply(lambda l: cleanse.read_list_from_str(l))\n",
    "\n",
    "countries_names['manufacturing_place_cleaned'] = \\\n",
    "                        countries_names.manufacturing_place_cleaned.apply(lambda l: cleanse.read_list_from_str(l))\n",
    "\n",
    "countries_names['purchase_places_cleaned'] = \\\n",
    "                        countries_names.purchase_places_cleaned.apply(lambda l: cleanse.read_list_from_str(l))\n",
    "\n",
    "food_facts_pd = food_facts_pd.drop(['countries_en',\n",
    "                                   'origins_tags', \n",
    "                                    'manufacturing_places_tags',\n",
    "                                    'purchase_places'],\n",
    "                                    axis=1)\n",
    "\n",
    "food_facts_pd['origins'] = countries_names.origins_cleaned\n",
    "food_facts_pd['manufacturing_places'] = countries_names.manufacturing_place_cleaned\n",
    "food_facts_pd['purchase_places'] = countries_names.purchase_places_cleaned\n",
    "food_facts_pd.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last touch - be frank about unknown countries\n",
    "food_facts_pd[['origins', 'manufacturing_places', 'purchase_places']] = \\\n",
    "    food_facts_pd[['origins', 'manufacturing_places', 'purchase_places']].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write cleaned datasets to CSV file\n",
    "clean_data_file_name = \"./data/openfoodfacts_clean.csv\"\n",
    "food_facts_pd.to_csv(clean_data_file_name, sep='\\t', encoding='utf-8')\n",
    "\n",
    "processed_carbon_data_file_name = \"./data/carbon_footprint_clean.csv\"\n",
    "eaternity_pd.to_csv(processed_carbon_data_file_name, sep='\\t', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
