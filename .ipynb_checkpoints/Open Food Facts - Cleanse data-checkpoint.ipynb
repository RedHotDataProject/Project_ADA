{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Our generated code\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from libs import exploring as explore\n",
    "from libs import visualising as visualize\n",
    "from libs import cleansing as cleanse\n",
    "\n",
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "open_food_facts_csv_file = \"./data/en.openfoodfacts.org.products.csv\"\n",
    "\n",
    "# Load list of columns (external file) that are loaded into pyspark\n",
    "data = []\n",
    "with open(\"./data/cleanse/columns_to_import.txt\", \"r\") as json_data:\n",
    "    columns_to_import = json.load(json_data)\n",
    "    columns_to_import\n",
    "\n",
    "\n",
    "food_facts_pd = pd.read_csv(open_food_facts_csv_file,\n",
    "                            delimiter=\"\\t\",\n",
    "                            usecols=columns_to_import.keys(),\n",
    "                            dtype=columns_to_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary_string = \"The dataset now comprises {} entries, of which we have {} features.\"\n",
    "data_summary_string.format(food_facts_pd.shape[0], food_facts_pd.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display number of NaN entries per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_entries = pd.DataFrame({'columns' : food_facts_pd.columns,\n",
    "                             'not nan_values' : [food_facts_pd[c].count() for c in food_facts_pd]\n",
    "                            })\n",
    "\n",
    "# Plot NaNs counts\n",
    "if PLOT:\n",
    "    null_entries.set_index('columns').plot(kind='barh', figsize=(10, 10))\n",
    "    plt.title(\"Not null values count in each column\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are many NaN entries in this data set. For our analysis, we can only use entries that have at least a product name, country tag, manufacturing and purchase place, and a created date tag. Unfortunately, we have to drop all columns, that lack those data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_rows_inital = food_facts_pd.shape[0]\n",
    "\n",
    "# Drop entries with missing entries in of our main-features\n",
    "essential_columns = ['created_t', 'product_name', 'countries_en', 'categories_en', 'manufacturing_places', 'purchase_places']\n",
    "food_facts_pd = food_facts_pd.dropna(subset=essential_columns, )\n",
    "\n",
    "no_rows_reduced_nan = food_facts_pd.shape[0]\n",
    "\n",
    "# Also drop duplicated values (indentify based on index (barcode))\n",
    "food_facts_pd = food_facts_pd.drop_duplicates()\n",
    "\n",
    "no_rows_reduced_duplicates = food_facts_pd.shape[0]\n",
    "\n",
    "print(\"{} entries were dropped, of which {} were duplicates.\"\\\n",
    "      .format(no_rows_inital-no_rows_reduced_duplicates, no_rows_reduced_nan-no_rows_reduced_duplicates))\n",
    "print(data_summary_string.format(food_facts_pd.shape[0], food_facts_pd.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puhh, that was though. From now on, we are going to rescue the data and enrich wherever we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs with emptry string\n",
    "food_facts_pd = food_facts_pd.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next lets look at the data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that we are not really keen of are the language indicators, so we are going to remove those abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_language_indicator(row_str):\n",
    "    tags = [tag if len(tag.split(':'))==1 else tag.split(':')[1] for tag in row_str.split(',')]\n",
    "    return \",\".join(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd.categories_en = food_facts_pd.categories_en.apply(remove_language_indicator)\n",
    "food_facts_pd.main_category = food_facts_pd.main_category.apply(remove_language_indicator)\n",
    "food_facts_pd.countries_en = food_facts_pd.countries_en.apply(remove_language_indicator)\n",
    "food_facts_pd.labels_en = food_facts_pd.labels_en.apply(remove_language_indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next issue we are going to tackel are redudant columns. Especially here, these are similarly named columns ending with \"_en\", \"_tags\". We are handling this, by only importing columns that end with \"_en\" if we have the choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unitize tags\n",
    "Many parts of the data are categorizations based on tags. However, those tags are in a variety of languages and string formattings, so in order to use them we attempt to group tags that hint to the same property and map them to a common indicator. \n",
    "\n",
    "Every column of the data set requires special treatment, as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd = food_facts_pd.dropna(subset=['product_name', 'countries_en', 'stores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note :  \n",
    "- purchase_places and countries_en are the same though \"countries_en\" is more complete\n",
    "-  manufacturing_places and origins are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"_Countries_\" is a csv file modified in the \"_Country__names.ipynb_\" file from the source (available at https://mledoze.github.io/countries/). We need to harmonise country names (and push them to English since many entries use French and German). The columns requiring our attentions are the following :\n",
    "- origins\n",
    "- manufacturing_places\n",
    "- countries_en\n",
    "\n",
    "Note that there each have a respective redundant column : origins_tags, manufacturing_places_tags and purchase_places. They are gonna be filtered by a function from our _cleansing.py_ library to lead to the following respective columns:\n",
    "- origins_cleaned\n",
    "- manufacturing_place_cleaned\n",
    "- purchase_places_cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd['origins_cleaned'] = food_facts_pd.origins\n",
    "food_facts_pd['manufacturing_place_cleaned'] = food_facts_pd.manufacturing_places\n",
    "food_facts_pd['purchase_places_cleaned'] = food_facts_pd.countries_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading analyse file\n",
    "countries = pd.read_csv(\"./data/country_lookup.csv\")[['name', 'cca2', 'alias', 'Forced']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a test to see how complete the harmonisation is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "copy_purchases_places = food_facts_pd[['purchase_places']].iloc[:1500, :]\n",
    "#copy_purchases_places = copy_purchases_places.replace('', \"Unknown\", regex=True)\n",
    "copy_purchases_places['Filtered'] = copy_purchases_places.purchase_places.apply(lambda x: cleanse.country_name_filter(x, countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_assignement = copy_purchases_places[copy_purchases_places.Filtered.apply(lambda l: l[0] == \"Unknown\")]\n",
    "print(\"Percentage of entries not assigned is {0:.2f}%\" .format(no_assignement.shape[0]/copy_purchases_places.shape[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's attack the Open Food Fact database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following commands should not be run except if the analysis has to be performed again. \n",
    "#Access the result in ./data/food_facts_pd_countries_names.csv (will be saved to that)\n",
    "######################################################\n",
    "run = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( run ):\n",
    "    food_facts_pd.origins_cleaned = food_facts_pd.origins_cleaned.apply(lambda x: cleanse.country_name_filter(x, countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( run ):\n",
    "    food_facts_pd.manufacturing_place_cleaned = food_facts_pd.manufacturing_place_cleaned.apply(lambda x: cleanse.country_name_filter(x, countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if( run ):\n",
    "    food_facts_pd.purchase_places_cleaned = food_facts_pd.purchase_places_cleaned.apply(lambda x: cleanse.country_name_filter(x, countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save these columns so that we don't have to run them again. \n",
    "\n",
    "#Do not run this command if you have not processed the whole dataset !\n",
    "if( run ):\n",
    "    food_facts_pd_countries_names = food_facts_pd[['origins_cleaned', 'manufacturing_place_cleaned', 'purchase_places_cleaned']]\n",
    "    food_facts_pd_countries_names.to_csv(\"./data/food_facts_pd_countries_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.plot_occurences_of_distinct_values(food_facts_pd, 'origins_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.plot_occurences_of_distinct_values(food_facts_pd, 'manufacturing_place_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.plot_occurences_of_distinct_values(food_facts_pd, 'purchase_places_cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unitze labels\n",
    "with open('./data/cleanse/taxonomies.json', 'r') as json_data:\n",
    "    labels_lookup = cleanse.to_lookup(json.load(json_data))\n",
    "food_facts_pd.labels_en = food_facts_pd.labels_en.apply(lambda x: \",\".join([labels_lookup[z] for z in x.split(',')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    _,_ = visualize.plot_occurences_of_distinct_values(food_facts_pd, 'labels_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store labels tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unitize store labels\n",
    "with open('./data/cleanse/stores_lookup.json', 'r') as json_data:\n",
    "    stores_lookup = cleanse.to_lookup(json.load(json_data))\n",
    "food_facts_pd.stores = food_facts_pd.stores.fillna(\"\").apply(lambda x: \",\".join([stores_lookup[z] for z in x.split(',')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    _,_ = visualize.plot_occurences_of_distinct_values(food_facts_pd, 'stores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food category tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    _,_ = visualize.plot_occurences_of_distinct_values(food_facts_pd, 'categories_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carbon footprint dataset\n",
    "\n",
    "Because the food facts database lacks carbon footprint specifications, we got random samples of products from Eaternity database. The goal afterward is to match Food Facts Database and Carbon Footprint database. First, let's take a look at the Carbon Footprint database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "carbon_footprint_csv_file = \"./data/carbon_footprint.csv\"\n",
    "\n",
    "carbon_footprint_pd = pd.read_csv(carbon_footprint_csv_file,\n",
    "                            delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_footprint_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have {0} ecological features for {1} products.'\\\n",
    "      .format(carbon_footprint_pd.shape[1], \n",
    "              carbon_footprint_pd.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_footprint_pd.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The title of each product is in german. If we want to match with the previous dataset with some keywords for exemple, we should translate into the same language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install py-translate\n",
    "from translate import translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_row(row):\n",
    "    translation = translator('de', 'en', row)\n",
    "\n",
    "for i, row in enumerate(carbon_footprint_pd['Title']):\n",
    "    print(i,row)\n",
    "   #  carbon_footprint_pd.loc[i] = translate_row(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_footprint_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_footprint_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = carbon_footprint_pd['CO2-Value [gram CO2/serving]'].hist(bins=50)\n",
    "ax.set_xlabel('Carbon footprint')\n",
    "ax.set_ylabel('Occurencies')\n",
    "ax.set_title('Distribution of the carbon ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat price info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\"./web_crawler/data/prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_reduced = prices[['code', 'price_per_100', 'store_currency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd = food_facts_pd.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd.code = pd.to_numeric(food_facts_pd.code, errors='coerce').fillna(0).clip_upper(sys.maxsize).astype('int')\n",
    "prices_reduced.code = prices_reduced.code.clip_upper(sys.maxsize).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd = pd.merge(food_facts_pd, prices_reduced, left_on='code', right_on='code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Product prices successfully merged: {}\".format(food_facts_pd.price_per_100.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove negative entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = food_facts_pd.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns\n",
    "\n",
    "food_facts_pd[numeric_columns] = food_facts_pd[numeric_columns].where(food_facts_pd[numeric_columns] < 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write clean data frame to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataframe that extracts all information required by the web crawler\n",
    "if 1==0: # skip cell\n",
    "    products = food_facts_pd\n",
    "\n",
    "    products.to_pickle(\"./web_crawler/products_pd.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : country names harmonised are available in ./data/food_facts_pd_countries_names.csv (note the additional code to go back to a list of strings). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply country name filter\n",
    "\n",
    "countries_names= pd.read_csv(\"./data/food_facts_pd_countries_names.csv\")\n",
    "countries_names.origins_cleaned = \\\n",
    "                        countries_names.origins_cleaned.apply(lambda l: cleanse.read(l))\n",
    "\n",
    "countries_names.manufacturing_place_cleaned = \\\n",
    "                        countries_names.manufacturing_place_cleaned.apply(lambda l: cleanse.read(l))\n",
    "\n",
    "countries_names.purchase_places_cleaned = \\\n",
    "                        countries_names.purchase_places_cleaned.apply(lambda l: cleanse.read(l))\n",
    "\n",
    "food_facts_pd.drop(['origins', 'manufacturing_places', 'countries_en'], axis=1)\n",
    "food_facts_pd['origins_cleaned'] = countries_names.origins_cleaned\n",
    "food_facts_pd['manufacturing_place_cleaned'] = countries_names.manufacturing_place_cleaned\n",
    "food_facts_pd['purchase_places_cleaned'] = countries_names.purchase_places_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV file\n",
    "clean_data_file_name = \"./data/openfoodfacts_clean.csv\"\n",
    "food_facts_pd.to_csv(clean_data_file_name, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_facts_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_footprints = food_facts_pd[food_facts_pd['carbon-footprint_100g'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carbon_footprints[carbon_footprints['stores'].str.contains('Migros')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_reduced[prices_reduced['store_currency']=='CHF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ada",
   "language": "python",
   "name": "ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
