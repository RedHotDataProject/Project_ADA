{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Our generated code\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_crawler.scraper_migros import MigrosScraper\n",
    "from web_crawler.scraper_cora import CoraScraper\n",
    "from web_crawler.scraper_coop import CoopScraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape prices from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_pickle(\"./data/products_pd.pickle\")\n",
    "products.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# products.loc[products[\"stores\"].apply({\"Migros\"}.issubset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "products.product_name = products.product_name.fillna(\"\")\n",
    "# products.brands = products.brands.fillna(\"\")\n",
    "\n",
    "migros = MigrosScraper()\n",
    "# cora = CoraScraper()\n",
    "\n",
    "counter = 0;\n",
    "\n",
    "with open('./data/scraped_products_migros_carbon.json', mode='w', encoding='utf-8') as f:\n",
    "\n",
    "    for i, row in products.iterrows():\n",
    "        if \"Migros\" in row.stores:\n",
    "            counter = counter +1\n",
    "            query = row['product_name']\n",
    "            try:\n",
    "                product_dict = migros.search(query)\n",
    "                product_dict['code'] = str(row.name)\n",
    "                product_dict['product_name'] = row.product_name\n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "                continue\n",
    "                \n",
    "            f.write(json.dumps(product_dict)) # use `json.loads` to do the reverse\n",
    "            sleep(randint(1,5))\n",
    "\n",
    "            \n",
    "        elif (\"Cora\" in row.stores) & (1==0): # skip for this run\n",
    "            query = row['product_name']\n",
    "            print(query.title())\n",
    "            try:\n",
    "                product_dict = cora.search(query)\n",
    "                product_dict['code'] = row.name\n",
    "                product_dict['product_name'] = row.product_name\n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "                continue\n",
    "                \n",
    "            f.write(json.dumps(product_dict) + ',') # use `json.loads` to do the reverse\n",
    "            \n",
    "            # We don't wanna get banned from the server\n",
    "            sleep(randint(1,10))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzyset import FuzzySet\n",
    "\n",
    "def compute_match_score(product_name_list, store_name_list):\n",
    "    \n",
    "    if product_name_list and store_name_list:\n",
    "        name_fs = FuzzySet(store_name_list)\n",
    "        name_score = [0 if name_fs.get(i)==None else name_fs.get(i)[0][0] for i in product_name_list]\n",
    "        return sum(name_score) / len(name_score)  \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migros data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/scraped_products_migros_carbon.json', mode='r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    \n",
    "migros_products = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# If it has no quantity, it is not a food item, so drop it\n",
    "migros_products = migros_products[migros_products['store_quantity'] != \"\"]\n",
    "\n",
    "print(migros_products.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prices numeric (2 price formats)\n",
    "migros_products.store_price = pd.to_numeric(migros_products['store_price']\\\n",
    "                                            .apply(lambda x: x.split('.â€“')[0]),\n",
    "                                            errors=\"raise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the dirty part of the Migros scraped data. We need to know the quantity of the product, to be able to scale the price, however, it is embedded in text. I try to make clear what is to be done with my code comments, but I guess it would be helpful if you take a look at the data (above) first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the quantity of items sold numeric\n",
    "migros_products['amount'] = pd.to_numeric(migros_products['store_quantity']\\\n",
    "                                            .apply(lambda x: x.split('x')[0]),\n",
    "                                            errors=\"coerce\").fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migros_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the quantity per item\n",
    "\n",
    "# Remove space between number and g or ml unit\n",
    "migros_products['store_quantity'] = migros_products['store_quantity'].apply(lambda x: \"\".join(x.split()))\n",
    "\n",
    "# Extract quantity per item. The number is bound between 1 and 1000, since the unit measure are metric.\n",
    "migros_products['item_quantity'] = pd.to_numeric(migros_products['store_quantity'].str.extract(r'([0-9]{1,3})[gmlk]', expand=False), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_migros_price_per_100(row):\n",
    "        \n",
    "    quantity = row.amount * row.item_quantity\n",
    "    if row.store_unit == 'g' or row.store_unit == 'm':\n",
    "        # Unit in gramm / milliliter -> correct unit\n",
    "        quantity *= 1        \n",
    "    elif row.store_unit == 'k' or row.store_unit == 'l':\n",
    "\n",
    "        # Unit in kilogramm / liter -> convert unit\n",
    "        quantity *= 1000\n",
    "\n",
    "    # Price as multiples of 100 gramms / milliliters\n",
    "    return row.store_price / quantity * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migros_products['store_unit'] = migros_products['store_quantity'].str.extract(r'[\\d]([gmlk])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "migros_products['price_per_100'] = migros_products.apply(compute_migros_price_per_100, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The webcrawl was automated, so oftentimes we will have selected unrelated items with our search queries. In the following, we quantify our confidence into a item referring to the product in the Open Food Facts database. Currently, we are doing this only by comparing the name strings. We would be safer, if we could also compare the categories. However, they are oftentimes in German/French, while the database is in English and the google translate python API has a bug, and the pull request is still pending (https://github.com/ssut/py-googletrans/pull/78). We are going to improve our matching method, once this issue is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migros_products['match_scores'] \\\n",
    "    = migros_products.apply(lambda row: compute_match_score(row.product_name.lower().split(),\n",
    "                                                            row.store_name.lower().split()), \n",
    "                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "migros_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monoprix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/scraped_products_monoprix.json', mode='r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "monoprix_products = pd.DataFrame.from_dict(data)\n",
    "\n",
    "monoprix_products = monoprix_products[monoprix_products['store_currency']=='EURO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make price numeric\n",
    "monoprix_products.store_price = monoprix_products.store_price.apply(lambda x: float(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monoprix_price_per_100(store_quantity_str):\n",
    "    tokens = str(store_quantity_str).split()\n",
    "    if \"litre\" in tokens or \"kg\" in tokens:\n",
    "        return float(tokens[-2])/100\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute price per 100gr/ml\n",
    "monoprix_products['price_per_100'] = monoprix_products.store_quantity.apply(monoprix_price_per_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confidence that the scraped item is the same as in the open food facts database\n",
    "monoprix_products['match_scores'] = monoprix_products.apply(lambda row: compute_match_score(row.product_name.lower().split(),\n",
    "                                                               row.store_name.lower().split('-')), \n",
    "                                                           axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monoprix_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = migros_products[['code', 'product_name', 'store_currency', 'price_per_100', 'match_scores']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.concat([prices, \n",
    "                    monoprix_products[['code', 'product_name', 'store_currency', 'price_per_100', 'match_scores']]\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only export items with a credible match score (threhsold found from trial and error)\n",
    "prices_filtered = prices[prices['match_scores']>0.0]\n",
    "prices_filtered.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './data/prices.csv'\n",
    "prices_filtered.set_index('code').to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testbed for new website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://search.migros.ch/de/q:\"\n",
    "\n",
    "driver = webdriver.Firefox(executable_path='/home/kingkolibri/Programs/geckodriver')\n",
    "driver.implicitly_wait(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Chocolate Chip Shortbread\"\n",
    "\n",
    "driver.get(BASE_URL + query )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find object on search results page\n",
    "python_button = driver.find_element_by_css_selector(\n",
    "    '.mui-list-products-wide > li:nth-child(1) > a:nth-child(1)')  # First article in grid view\n",
    "python_button.click()  # click link\n",
    "\n",
    "# Hand the page source to Beautiful Soup\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(soup.select_one('.sidebar-product-name').text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select_one('.current-price').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join(soup.select_one('p.sidebar-subtext').text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select_one('.mui-breadcrumb').text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = soup.select_one('#title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'-'.join([i.text for i in soup.select_one('#title').findAll('span')[:-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
